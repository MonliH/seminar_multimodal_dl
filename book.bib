@Manual{rlang,
  title = {R: A Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  organization = {R Foundation for Statistical Computing},
  address = {Vienna, Austria},
  year = {2018},
  url = {https://www.R-project.org/},
}



@INPROCEEDINGS{radford2021learning,
  AUTHOR = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  ORGANIZATION = {PMLR},
  BOOKTITLE = {International Conference on Machine Learning},
  DATE = {2021},
  PAGES = {8748--8763},
  TITLE = {Learning transferable visual models from natural language supervision},
}

@ARTICLE{baevski2022data2vec,
  AUTHOR = {Baevski, Alexei and Hsu, Wei-Ning and Xu, Qiantong and Babu, Arun and Gu, Jiatao and Auli, Michael},
  DATE = {2022},
  JOURNALTITLE = {arXiv preprint arXiv:2202.03555},
  TITLE = {Data2vec: A general framework for self-supervised learning in speech, vision and language},
}

@ARTICLE{vaswani2017attention,
  AUTHOR = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {≈Å}ukasz and Polosukhin, Illia},
  DATE = {2017},
  JOURNALTITLE = {Advances in neural information processing systems},
  TITLE = {Attention is all you need},
  VOLUME = {30},
}

@article{bao2021beit,
  title={Beit: Bert pre-training of image transformers},
  author={Bao, Hangbo and Dong, Li and Wei, Furu},
  journal={arXiv preprint arXiv:2106.08254},
  year={2021}
}

@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@article{sennrich2015neural,
  title={Neural machine translation of rare words with subword units},
  author={Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
  journal={arXiv preprint arXiv:1508.07909},
  year={2015}
}

@article{baevski2020wav2vec,
  title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author={Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={12449--12460},
  year={2020}
}

@article{wang2018glue,
  title={GLUE: A multi-task benchmark and analysis platform for natural language understanding},
  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R},
  journal={arXiv preprint arXiv:1804.07461},
  year={2018}
}

@inproceedings{chen2021empirical,
  title={An empirical study of training self-supervised vision transformers},
  author={Chen, Xinlei and Xie, Saining and He, Kaiming},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9640--9649},
  year={2021}
}

@inproceedings{caron2021emerging,
  title={Emerging properties in self-supervised vision transformers},
  author={Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J{\'e}gou, Herv{\'e} and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9650--9660},
  year={2021}
}

@inproceedings{he2022masked,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16000--16009},
  year={2022}
}

@inproceedings{wei2022masked,
  title={Masked feature prediction for self-supervised visual pre-training},
  author={Wei, Chen and Fan, Haoqi and Xie, Saining and Wu, Chao-Yuan and Yuille, Alan and Feichtenhofer, Christoph},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14668--14678},
  year={2022}
}

@inproceedings{jaegle2021perceiver,
  title={Perceiver: General perception with iterative attention},
  author={Jaegle, Andrew and Gimeno, Felix and Brock, Andy and Vinyals, Oriol and Zisserman, Andrew and Carreira, Joao},
  booktitle={International conference on machine learning},
  pages={4651--4664},
  year={2021},
  organization={PMLR}
}

@ARTICLE{dosovitskiy2020image,
  AUTHOR = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  DATE = {2020},
  JOURNALTITLE = {arXiv preprint arXiv:2010.11929},
  TITLE = {An image is worth 16x16 words: Transformers for image recognition at scale},
}

@ARTICLE{alayrac2022flamingo,
  AUTHOR = {Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katie and Reynolds, Malcolm and others},
  DATE = {2022},
  JOURNALTITLE = {arXiv preprint arXiv:2204.14198},
  TITLE = {Flamingo: a visual language model for few-shot learning},
}

@ARTICLE{lu2019vilbert,
  AUTHOR = {Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  DATE = {2019},
  JOURNALTITLE = {Advances in neural information processing systems},
  TITLE = {Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks},
  VOLUME = {32},
}

@ARTICLE{uppal2022multimodal,
  AUTHOR = {Uppal, Shagun and Bhagat, Sarthak and Hazarika, Devamanyu and Majumder, Navonil and Poria, Soujanya and Zimmermann, Roger and Zadeh, Amir},
  PUBLISHER = {Elsevier},
  DATE = {2022},
  JOURNALTITLE = {Information Fusion},
  PAGES = {149--171},
  TITLE = {Multimodal research in vision and language: A review of current and emerging trends},
  VOLUME = {77},
}

@article{hoffmann2022training,
  title={Training Compute-Optimal Large Language Models},
  author={Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and Casas, Diego de Las and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and others},
  journal={arXiv preprint arXiv:2203.15556},
  year={2022}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@inproceedings{jia2021scaling,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle={International Conference on Machine Learning},
  pages={4904--4916},
  year={2021},
  organization={PMLR}
}

@article{perez2021true,
  title={True few-shot learning with language models},
  author={Perez, Ethan and Kiela, Douwe and Cho, Kyunghyun},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={11054--11070},
  year={2021}
}

@article{zeng2022socratic,
  title={Socratic models: Composing zero-shot multimodal reasoning with language},
  author={Zeng, Andy and Wong, Adrian and Welker, Stefan and Choromanski, Krzysztof and Tombari, Federico and Purohit, Aveek and Ryoo, Michael and Sindhwani, Vikas and Lee, Johnny and Vanhoucke, Vincent and others},
  journal={arXiv preprint arXiv:2204.00598},
  year={2022}
}

@article{ren2015faster,
  title={Faster r-cnn: Towards real-time object detection with region proposal networks},
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}


@inproceedings{krishnavisualgenome,
  title={Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations},
  author={Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and Bernstein, Michael and Fei-Fei, Li},
  year = {2016},
  url = {https://arxiv.org/abs/1602.07332},
}

@article{sikarwar2022efficacy,
  title={On the efficacy of co-attention transformer layers in visual question answering},
  author={Sikarwar, Ankur and Kreiman, Gabriel},
  journal={arXiv preprint arXiv:2201.03965},
  year={2022}
}

@article{chowdhery2022palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022}
}

@article{das2017human,
  title={Human attention in visual question answering: Do humans and deep networks look at the same regions?},
  author={Das, Abhishek and Agrawal, Harsh and Zitnick, Larry and Parikh, Devi and Batra, Dhruv},
  journal={Computer Vision and Image Understanding},
  volume={163},
  pages={90--100},
  year={2017},
  publisher={Elsevier}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}
