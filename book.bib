@Manual{rlang,
  title = {R: A Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  organization = {R Foundation for Statistical Computing},
  address = {Vienna, Austria},
  year = {2018},
  url = {https://www.R-project.org/},
}

<!-- references for chapter 2 -->
<!-- references for 2.1 -->
@inproceedings{cornia2020m2,
  title={{Meshed-Memory Transformer for Image Captioning}},
  author={Cornia, Marcella and Stefanini, Matteo and Baraldi, Lorenzo and Cucchiara, Rita},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2020}
}

@article{bordes2020incorporating,
  title={Incorporating visual semantics into sentence representations within a grounded space},
  author={Bordes, Patrick and Zablocki, Eloi and Soulier, Laure and Piwowarski, Benjamin and Gallinari, Patrick},
  journal={arXiv preprint arXiv:2002.02734},
  year={2020}
}

@article{harnad1990symbol,
  title={The symbol grounding problem},
  author={Harnad, Stevan},
  journal={Physica D: Nonlinear Phenomena},
  volume={42},
  number={1-3},
  pages={335--346},
  year={1990},
  publisher={Elsevier}
}

@InProceedings{mccoco,
author="Lin, Tsung-Yi
and Maire, Michael
and Belongie, Serge
and Hays, James
and Perona, Pietro
and Ramanan, Deva
and Doll{\'a}r, Piotr
and Zitnick, C. Lawrence",
editor="Fleet, David
and Pajdla, Tomas
and Schiele, Bernt
and Tuytelaars, Tinne",
title="Microsoft COCO: Common Objects in Context",
booktitle="Computer Vision -- ECCV 2014",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="740--755",
abstract="We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model.",
isbn="978-3-319-10602-1"
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@inproceedings{silberer2012grounded,
  title={Grounded models of semantic representation},
  author={Silberer, Carina and Lapata, Mirella},
  booktitle={Tsujii J, Henderson J, Pa{\c{s}}ca M, editors. Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning; 2012 Jul 12--14; Jeju Island, Korea. Stroudsburg: ACL; 2012. p. 1423-33.},
  year={2012},
  organization={ACL (Association for Computational Linguistics)}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{baevski2022data2vec,
  title={Data2vec: A general framework for self-supervised learning in speech, vision and language},
  author={Baevski, Alexei and Hsu, Wei-Ning and Xu, Qiantong and Babu, Arun and Gu, Jiatao and Auli, Michael},
  journal={arXiv preprint arXiv:2202.03555},
  year={2022}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@article{alayrac2022flamingo,
  title={Flamingo: a visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katie and Reynolds, Malcolm and others},
  journal={arXiv preprint arXiv:2204.14198},
  year={2022}
}

@article{lu2019vilbert,
  title={Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks},
  author={Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{uppal2022multimodal,
  title={Multimodal research in vision and language: A review of current and emerging trends},
  author={Uppal, Shagun and Bhagat, Sarthak and Hazarika, Devamanyu and Majumder, Navonil and Poria, Soujanya and Zimmermann, Roger and Zadeh, Amir},
  journal={Information Fusion},
  volume={77},
  pages={149--171},
  year={2022},
  publisher={Elsevier}
}

@InProceedings{ramesh2021dalle,
  title = 	 {Zero-Shot Text-to-Image Generation},
  author =       {Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {8821--8831},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/ramesh21a/ramesh21a.pdf},
  url = 	 {https://proceedings.mlr.press/v139/ramesh21a.html},
  abstract = 	 {Text-to-image generation has traditionally focused on finding better modeling assumptions for training on a fixed dataset. These assumptions might involve complex architectures, auxiliary losses, or side information such as object part labels or segmentation masks supplied during training. We describe a simple approach for this task based on a transformer that autoregressively models the text and image tokens as a single stream of data. With sufficient data and scale, our approach is competitive with previous domain-specific models when evaluated in a zero-shot fashion.}
}
@article{nichol2021glide,
  author    = {Alex Nichol and
               Prafulla Dhariwal and
               Aditya Ramesh and
               Pranav Shyam and
               Pamela Mishkin and
               Bob McGrew and
               Ilya Sutskever and
               Mark Chen},
  title     = {{GLIDE:} Towards Photorealistic Image Generation and Editing with
               Text-Guided Diffusion Models},
  journal   = {CoRR},
  volume    = {abs/2112.10741},
  year      = {2021},
  url       = {https://arxiv.org/abs/2112.10741},
  eprinttype = {arXiv},
  eprint    = {2112.10741},
  timestamp = {Tue, 04 Jan 2022 15:59:27 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2112-10741.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@misc{DeepPAMM,
  doi = {10.48550/ARXIV.2202.07423},
  
  url = {https://arxiv.org/abs/2202.07423},
  
  author = {Kopper, Philipp and Wiegrebe, Simon and Bischl, Bernd and Bender, Andreas and Rügamer, David},
  
  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {DeepPAMM: Deep Piecewise Exponential Additive Mixed Models for Complex Hazard Structures in Survival Analysis},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}
@INPROCEEDINGS{DeepConvSurv,
  author={Zhu, Xinliang and Yao, Jiawen and Huang, Junzhou},
  booktitle={2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={Deep convolutional neural network for survival analysis with pathological images}, 
  year={2016},
  volume={},
  number={},
  pages={544-547},
  doi={10.1109/BIBM.2016.7822579}
}
@InProceedings{DeepCorrSurv,
author="Yao, Jiawen
and Zhu, Xinliang
and Zhu, Feiyun
and Huang, Junzhou",
editor="Descoteaux, Maxime
and Maier-Hein, Lena
and Franz, Alfred
and Jannin, Pierre
and Collins, D. Louis
and Duchesne, Simon",
title="Deep Correlational Learning for Survival Prediction from Multi-modality Data",
booktitle="Medical Image Computing and Computer-Assisted Intervention − MICCAI 2017",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="406--414",
isbn="978-3-319-66185-8"
}
@article{WideandDeepSurvival,
  author    = {Sebastian P{\"{o}}lsterl and
               Ignacio Sarasua and
               Benjam{\'{\i}}n Guti{\'{e}}rrez{-}Becker and
               Christian Wachinger},
  title     = {A Wide and Deep Neural Network for Survival Analysis from Anatomical
               Shape and Tabular Clinical Data},
  journal   = {CoRR},
  volume    = {abs/1909.03890},
  year      = {2019},
  url       = {http://arxiv.org/abs/1909.03890},
  eprinttype = {arXiv},
  eprint    = {1909.03890},
  timestamp = {Sat, 23 Jan 2021 01:20:05 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1909-03890.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{DeepGaussianProcessCropPred,
author = {You, Jiaxuan and Li, Xiaocheng and Low, Melvin and Lobell, David and Ermon, Stefano},
title = {Deep Gaussian Process for Crop Yield Prediction Based on Remote Sensing Data},
year = {2017},
publisher = {AAAI Press},
abstract = {Agricultural monitoring, especially in developing countries, can help prevent famine and support humanitarian efforts. A central challenge is yield estimation, i.e., predicting crop yields before harvest.We introduce a scalable, accurate, and inexpensive method to predict crop yields using publicly available remote sensing data. Our approach improves existing techniques in three ways. First, we forego hand-crafted features traditionally used in the remote sensing community and propose an approach based on modern representation learning ideas. We also introduce a novel dimensionality reduction technique that allows us to train a Convolutional Neural Network or Long-short Term Memory network and automatically learn useful features even when labeled training data are scarce. Finally, we incorporate a Gaussian Process component to explicitly model the spatio-temporal structure of the data and further improve accuracy. We evaluate our approach on county-level soybean yield prediction in the U.S. and show that it outperforms competing techniques.},
booktitle = {Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence},
pages = {4559–4565},
numpages = {7},
location = {San Francisco, California, USA},
series = {AAAI'17}
}
@article{Law_2019,
	doi = {10.1145/3342240},
  
	url = {https://doi.org/10.1145%2F3342240},
  
	year = 2019,
	month = {sep},
  
	publisher = {Association for Computing Machinery ({ACM})},
  
	volume = {10},
  
	number = {5},
  
	pages = {1--19},
  
	author = {Stephen Law and Brooks Paige and Chris Russell},
  
	title = {Take a Look Around},
  
	journal = {{ACM} Transactions on Intelligent Systems and Technology}
}
@article{JeanEtAl,
author = {Neal Jean  and Marshall Burke  and Michael Xie  and W. Matthew Davis  and David B. Lobell  and Stefano Ermon },
title = {Combining satellite imagery and machine learning to predict poverty},
journal = {Science},
volume = {353},
number = {6301},
pages = {790-794},
year = {2016},
doi = {10.1126/science.aaf7894},
URL = {https://www.science.org/doi/abs/10.1126/science.aaf7894},
eprint = {https://www.science.org/doi/pdf/10.1126/science.aaf7894}
}
@article{Sardelich2018MultimodalDL,
  title={Multimodal deep learning for short-term stock volatility prediction},
  author={Marcelo Sardelich and Suresh Manandhar},
  journal={ArXiv},
  year={2018},
  volume={abs/1812.10479}
}
@inproceedings{WideDeepNN,
author = {Cheng, Heng-Tze and Koc, Levent and Harmsen, Jeremiah and Shaked, Tal and Chandra, Tushar and Aradhye, Hrishi and Anderson, Glen and Corrado, Greg and Chai, Wei and Ispir, Mustafa and Anil, Rohan and Haque, Zakaria and Hong, Lichan and Jain, Vihan and Liu, Xiaobing and Shah, Hemal},
title = {Wide &amp; Deep Learning for Recommender Systems},
year = {2016},
isbn = {9781450347952},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2988450.2988454},
doi = {10.1145/2988450.2988454},
booktitle = {Proceedings of the 1st Workshop on Deep Learning for Recommender Systems},
pages = {7–10},
numpages = {4},
keywords = {Wide &amp; Deep Learning, Recommender Systems},
location = {Boston, MA, USA},
series = {DLRS 2016}
}
@misc{SSDDR,
  doi = {10.48550/ARXIV.2002.05777},
  
  url = {https://arxiv.org/abs/2002.05777},
  
  author = {Rügamer, David and Kolb, Chris and Klein, Nadja},
  
  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), Methodology (stat.ME), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Semi-Structured Distributional Regression -- Extending Structured Additive Models by Arbitrary Deep Neural Networks and Data Modalities},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}
@article{HuangEtAl,
author = {Huang, Shih-Cheng and Pareek, Anuj and Seyyedi, Saeed and Banerjee, Imon and Lungren, Matthew},
year = {2020},
month = {12},
pages = {},
title = {Fusion of medical imaging and electronic health records using deep learning: a systematic review and implementation guidelines},
volume = {3},
journal = {npj Digital Medicine},
doi = {10.1038/s41746-020-00341-z}
}
@article{GoogleMappingBuilding,
  author    = {Wojciech Sirko and
               Sergii Kashubin and
               Marvin Ritter and
               Abigail Annkah and
               Yasser Salah Eddine Bouchareb and
               Yann N. Dauphin and
               Daniel Keysers and
               Maxim Neumann and
               Moustapha Ciss{\'{e}} and
               John Quinn},
  title     = {Continental-Scale Building Detection from High Resolution Satellite
               Imagery},
  journal   = {CoRR},
  volume    = {abs/2107.12283},
  year      = {2021},
  url       = {https://arxiv.org/abs/2107.12283},
  eprinttype = {arXiv},
  eprint    = {2107.12283},
  timestamp = {Tue, 03 Aug 2021 09:13:02 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2107-12283.bib},

<!-- references for 2.4 -->

@article{bommasani2021opportunities,
  title={On the opportunities and risks of foundation models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal={arXiv preprint arXiv:2108.07258},
  year={2021}
}

@article{yuan2021florence,
  title={Florence: A New Foundation Model for Computer Vision},
  author={Yuan, Lu and Chen, Dongdong and Chen, Yi-Ling and Codella, Noel and Dai, Xiyang and Gao, Jianfeng and Hu, Houdong and Huang, Xuedong and Li, Boxin and Li, Chunyuan and others},
  journal={arXiv preprint arXiv:2111.11432},
  year={2021}
}

@article{yu2022coca,
  title={CoCa: Contrastive Captioners are Image-Text Foundation Models},
  author={Yu, Jiahui and Wang, Zirui and Vasudevan, Vijay and Yeung, Legg and Seyedhosseini, Mojtaba and Wu, Yonghui},
  journal={arXiv preprint arXiv:2205.01917},
  year={2022}
}
@Article{Mikolov2013,
  author      = {Tomas Mikolov and Kai Chen and Greg Corrado and Jeffrey Dean},
  title       = {Efficient Estimation of Word Representations in Vector Space},
  year        = {2013},
  abstract    = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
  date        = {2013-01-16},
  eprint      = {1301.3781},
  eprintclass = {cs.CL},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1301.3781v3:PDF},
  keywords    = {cs.CL},
}

@Article{Bojanowski2016,
  author      = {Piotr Bojanowski and Edouard Grave and Armand Joulin and Tomas Mikolov},
  title       = {Enriching Word Vectors with Subword Information},
  year        = {2016},
  abstract    = {Continuous word representations, trained on large unlabeled corpora are useful for many natural language processing tasks. Popular models that learn such representations ignore the morphology of words, by assigning a distinct vector to each word. This is a limitation, especially for languages with large vocabularies and many rare words. In this paper, we propose a new approach based on the skipgram model, where each word is represented as a bag of character $n$-grams. A vector representation is associated to each character $n$-gram; words being represented as the sum of these representations. Our method is fast, allowing to train models on large corpora quickly and allows us to compute word representations for words that did not appear in the training data. We evaluate our word representations on nine different languages, both on word similarity and analogy tasks. By comparing to recently proposed morphological word representations, we show that our vectors achieve state-of-the-art performance on these tasks.},
  date        = {2016-07-15},
  eprint      = {1607.04606},
  eprintclass = {cs.CL},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1607.04606v2:PDF},
  keywords    = {cs.CL, cs.LG},
}

@Article{Bahdanau2014,
  author      = {Dzmitry Bahdanau and Kyunghyun Cho and Yoshua Bengio},
  title       = {Neural Machine Translation by Jointly Learning to Align and Translate},
  year        = {2014},
  abstract    = {Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.},
  date        = {2014-09-01},
  eprint      = {1409.0473},
  eprintclass = {cs.CL},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1409.0473v7:PDF},
  keywords    = {cs.CL, cs.LG, cs.NE, stat.ML},
}

@Article{Sutskever2014,
  author      = {Ilya Sutskever and Oriol Vinyals and Quoc V. Le},
  title       = {Sequence to Sequence Learning with Neural Networks},
  year        = {2014},
  abstract    = {Deep Neural Networks (DNNs) are powerful models that have achieved excellent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets are available, they cannot be used to map sequences to sequences. In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. Our method uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. Our main result is that on an English to French translation task from the WMT'14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM's BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did not have difficulty on long sentences. For comparison, a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which is close to the previous best result on this task. The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the passive voice. Finally, we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM's performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier.},
  date        = {2014-09-10},
  eprint      = {1409.3215},
  eprintclass = {cs.CL},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1409.3215v3:PDF},
  keywords    = {cs.CL, cs.LG},
}

@Article{Devlin2018,
  author      = {Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
  title       = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  year        = {2018},
  abstract    = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
  date        = {2018-10-11},
  eprint      = {1810.04805},
  eprintclass = {cs.CL},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1810.04805v2:PDF},
  keywords    = {cs.CL},
}

@Article{Raffel2019,
  author      = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  title       = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  year        = {2019},
  abstract    = {Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts all text-based language problems into a text-to-text format. Our systematic study compares pre-training objectives, architectures, unlabeled data sets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new ``Colossal Clean Crawled Corpus'', we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our data set, pre-trained models, and code.},
  date        = {2019-10-23},
  eprint      = {1910.10683},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1910.10683v3:PDF},
  keywords    = {cs.LG, cs.CL, stat.ML},
}

@article{ResNet,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Deep Residual Learning for Image Recognition},
  journal   = {CoRR},
  volume    = {abs/1512.03385},
  year      = {2015},
  url       = {http://arxiv.org/abs/1512.03385},
  eprinttype = {arXiv},
  eprint    = {1512.03385},
  timestamp = {Wed, 17 Apr 2019 17:23:45 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/HeZRS15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{EfficientNet,
  author    = {Mingxing Tan and
               Quoc V. Le},
  title     = {EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1905.11946},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.11946},
  eprinttype = {arXiv},
  eprint    = {1905.11946},
  timestamp = {Mon, 03 Jun 2019 13:42:33 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1905-11946.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{SimCLR,
  author    = {Ting Chen and
               Simon Kornblith and
               Mohammad Norouzi and
               Geoffrey E. Hinton},
  title     = {A Simple Framework for Contrastive Learning of Visual Representations},
  journal   = {CoRR},
  volume    = {abs/2002.05709},
  year      = {2020},
  url       = {https://arxiv.org/abs/2002.05709},
  eprinttype = {arXiv},
  eprint    = {2002.05709},
  timestamp = {Fri, 14 Feb 2020 12:07:41 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2002-05709.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{SwAV,
  author    = {Mathilde Caron and
               Ishan Misra and
               Julien Mairal and
               Priya Goyal and
               Piotr Bojanowski and
               Armand Joulin},
  title     = {Unsupervised Learning of Visual Features by Contrasting Cluster Assignments},
  journal   = {CoRR},
  volume    = {abs/2006.09882},
  year      = {2020},
  url       = {https://arxiv.org/abs/2006.09882},
  eprinttype = {arXiv},
  eprint    = {2006.09882},
  timestamp = {Tue, 23 Jun 2020 17:57:22 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2006-09882.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
a service of  Schloss Dagstuhl - Leibniz Center for Informatics	homebrowsesearchabout

@article{BYOL,
  author    = {Jean{-}Bastien Grill and
               Florian Strub and
               Florent Altch{\'{e}} and
               Corentin Tallec and
               Pierre H. Richemond and
               Elena Buchatskaya and
               Carl Doersch and
               Bernardo {\'{A}}vila Pires and
               Zhaohan Daniel Guo and
               Mohammad Gheshlaghi Azar and
               Bilal Piot and
               Koray Kavukcuoglu and
               R{\'{e}}mi Munos and
               Michal Valko},
  title     = {Bootstrap Your Own Latent: {A} New Approach to Self-Supervised Learning},
  journal   = {CoRR},
  volume    = {abs/2006.07733},
  year      = {2020},
  url       = {https://arxiv.org/abs/2006.07733},
  eprinttype = {arXiv},
  eprint    = {2006.07733},
  timestamp = {Wed, 17 Jun 2020 14:28:54 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2006-07733.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
a service of  Schloss Dagstuhl - Leibniz Center for Informatics	homebrowsesearchabout

@article{ImageT,
  author    = {Alexey Dosovitskiy and
               Lucas Beyer and
               Alexander Kolesnikov and
               Dirk Weissenborn and
               Xiaohua Zhai and
               Thomas Unterthiner and
               Mostafa Dehghani and
               Matthias Minderer and
               Georg Heigold and
               Sylvain Gelly and
               Jakob Uszkoreit and
               Neil Houlsby},
  title     = {An Image is Worth 16x16 Words: Transformers for Image Recognition
               at Scale},
  journal   = {CoRR},
  volume    = {abs/2010.11929},
  year      = {2020},
  url       = {https://arxiv.org/abs/2010.11929},
  eprinttype = {arXiv},
  eprint    = {2010.11929},
  timestamp = {Fri, 20 Nov 2020 14:04:05 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2010-11929.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{carreira2022hierarchical,
  title   = {Hierarchical Perceiver},
  author  = {Joao Carreira and Skanda Koppula and Daniel Zoran and Adria Recasens and Catalin Ionescu and Olivier Henaff and Evan Shelhamer and Relja Arandjelovic and Matt Botvinick and Oriol Vinyals and Karen Simonyan and Andrew Zisserman and Andrew Jaegle},
  year    = {2022},
  journal = {arXiv preprint arXiv: Arxiv-2202.10890}
}

@inproceedings{DBLP:conf/icml/JaegleGBVZC21,
  author    = {Andrew Jaegle and Felix Gimeno and Andy Brock and Oriol Vinyals and Andrew Zisserman and Jo{\~{a}}o Carreira},
  editor    = {Marina Meila and Tong Zhang},
  title     = {Perceiver: General Perception with Iterative Attention},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning, {ICML} 2021, 18-24 July 2021, Virtual Event},
  series    = {Proceedings of Machine Learning Research},
  volume    = {139},
  pages     = {4651-4664},
  publisher = {{PMLR}},
  year      = {2021},
  url       = {http://proceedings.mlr.press/v139/jaegle21a.html},
  timestamp = {Wed, 25 Aug 2021 17:11:17 +0200},
  biburl    = {https://dblp.org/rec/conf/icml/JaegleGBVZC21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{jaegle2021perceiver,
  title   = {Perceiver IO: A General Architecture for Structured Inputs & Outputs},
  author  = {Andrew Jaegle and Sebastian Borgeaud and Jean-Baptiste Alayrac and Carl Doersch and Catalin Ionescu and David Ding and Skanda Koppula and Daniel Zoran and Andrew Brock and Evan Shelhamer and Olivier Hénaff and Matthew M. Botvinick and Andrew Zisserman and Oriol Vinyals and João Carreira},
  year    = {2022},
  journal = {ICLR}
}

@article{lecun2022path,
  title={A Path Towards Autonomous Machine Intelligence Version 0.9. 2, 2022-06-27},
  author={LeCun, Yann},
  year={2022}
}

@article{bachmann2022multimae,
  title   = {MultiMAE: Multi-modal Multi-task Masked Autoencoders},
  author  = {Roman Bachmann and David Mizrahi and Andrei Atanov and Amir Zamir},
  year    = {2022},
  journal = {arXiv preprint arXiv: Arxiv-2204.01678}
}

@article{yu2022coca,
  title   = {CoCa: Contrastive Captioners are Image-Text Foundation Models},
  author  = {Jiahui Yu and Zirui Wang and Vijay Vasudevan and Legg Yeung and Mojtaba Seyedhosseini and Yonghui Wu},
  year    = {2022},
  journal = {arXiv preprint arXiv: Arxiv-2205.01917}
}

@inproceedings{DBLP:conf/nips/AkbariYQCCCG21,
  author    = {Hassan Akbari and Liangzhe Yuan and Rui Qian and Wei{-}Hong Chuang and Shih{-}Fu Chang and Yin Cui and Boqing Gong},
  editor    = {Marc'Aurelio Ranzato and Alina Beygelzimer and Yann N. Dauphin and Percy Liang and Jennifer Wortman Vaughan},
  title     = {{VATT:} Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text},
  booktitle = {Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual},
  pages     = {24206-24221},
  year      = {2021},
  url       = {https://proceedings.neurips.cc/paper/2021/hash/cb3213ada48302953cb0f166464ab356-Abstract.html},
  timestamp = {Tue, 03 May 2022 16:20:49 +0200},
  biburl    = {https://dblp.org/rec/conf/nips/AkbariYQCCCG21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/jstsp/ZhangYHD20,
  author    = {Chao Zhang and Zichao Yang and Xiaodong He and Li Deng},
  title     = {Multimodal Intelligence: Representation Learning, Information Fusion, and Applications},
  journal   = {{IEEE} J. Sel. Top. Signal Process.},
  volume    = {14},
  number    = {3},
  pages     = {478-493},
  year      = {2020},
  url       = {https://doi.org/10.1109/JSTSP.2020.2987728},
  doi       = {10.1109/JSTSP.2020.2987728},
  timestamp = {Thu, 06 Aug 2020 21:45:41 +0200},
  biburl    = {https://dblp.org/rec/journals/jstsp/ZhangYHD20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{iv2021multimodal,
  title   = {Multimodal Classification: Current Landscape, Taxonomy and Future Directions},
  author  = {William C. Sleeman IV and Rishabh Kapoor and Preetam Ghosh},
  year    = {2021},
  journal = {arXiv preprint arXiv: Arxiv-2109.09020}
}

@article{baltrušaitis2017multimodal,
  title   = {Multimodal Machine Learning: A Survey and Taxonomy},
  author  = {Tadas Baltrušaitis and Chaitanya Ahuja and Louis-Philippe Morency},
  year    = {2017},
  journal = {arXiv preprint arXiv: Arxiv-1705.09406}
}

@article{DBLP:journals/pami/BengioCV13,
  author    = {Yoshua Bengio and Aaron C. Courville and Pascal Vincent},
  title     = {Representation Learning: {A} Review and New Perspectives},
  journal   = {{IEEE} Trans. Pattern Anal. Mach. Intell.},
  volume    = {35},
  number    = {8},
  pages     = {1798-1828},
  year      = {2013},
  url       = {https://doi.org/10.1109/TPAMI.2013.50},
  doi       = {10.1109/TPAMI.2013.50},
  timestamp = {Wed, 14 Nov 2018 10:51:00 +0100},
  biburl    = {https://dblp.org/rec/journals/pami/BengioCV13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{wu2022nuwainfinity,
  title   = {NUWA-Infinity: Autoregressive over Autoregressive Generation for Infinite Visual Synthesis},
  author  = {Chenfei Wu and Jian Liang and Xiaowei Hu and Zhe Gan and Jianfeng Wang and Lijuan Wang and Zicheng Liu and Yuejian Fang and Nan Duan},
  year    = {2022},
  journal = {arXiv preprint arXiv: Arxiv-2207.09814}
}

@article{wu2021nwa,
  title   = {NÜWA: Visual Synthesis Pre-training for Neural visUal World creAtion},
  author  = {Chenfei Wu and Jian Liang and Lei Ji and Fan Yang and Yuejian Fang and Daxin Jiang and Nan Duan},
  year    = {2021},
  journal = {arXiv preprint arXiv: Arxiv-2111.12417}
}

@inproceedings{Zhu_2022_CVPR,
  author    = {Zhu, Xizhou and Zhu, Jinguo and Li, Hao and Wu, Xiaoshi and Li, Hongsheng and Wang, Xiaohua and Dai, Jifeng},
  title     = {Uni-Perceiver: Pre-Training Unified Architecture for Generic Perception for Zero-Shot and Few-Shot Tasks},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  month     = {June},
  year      = {2022},
  pages     = {16804-16815}
}

@article{likhosherstov2021polyvit,
  title   = {PolyViT: Co-training Vision Transformers on Images, Videos and Audio},
  author  = {Valerii Likhosherstov and Anurag Arnab and Krzysztof Choromanski and Mario Lucic and Yi Tay and Adrian Weller and Mostafa Dehghani},
  year    = {2021},
  journal = {arXiv preprint arXiv: Arxiv-2111.12993}
}

@inproceedings{DBLP:conf/aaai/ZhangZ0CAP22,
  author    = {Zizhao Zhang and Han Zhang and Long Zhao and Ting Chen and Sercan {\"{O}}. Arik and Tomas Pfister},
  title     = {Nested Hierarchical Transformer: Towards Accurate, Data-Efficient and Interpretable Visual Understanding},
  booktitle = {Thirty-Sixth {AAAI} Conference on Artificial Intelligence, {AAAI} 2022, Thirty-Fourth Conference on Innovative Applications of Artificial Intelligence, {IAAI} 2022, The Twelveth Symposium on Educational Advances in Artificial Intelligence, {EAAI} 2022 Virtual Event, February 22 - March 1, 2022},
  pages     = {3417-3425},
  publisher = {{AAAI} Press},
  year      = {2022},
  url       = {https://ojs.aaai.org/index.php/AAAI/article/view/20252},
  timestamp = {Mon, 11 Jul 2022 16:09:32 +0200},
  biburl    = {https://dblp.org/rec/conf/aaai/ZhangZ0CAP22.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{wang2021multimodal,
  title   = {Multimodal Self-Supervised Learning of General Audio Representations},
  author  = {Luyu Wang and Pauline Luc and Adria Recasens and Jean-Baptiste Alayrac and Aaron van den Oord},
  year    = {2021},
  journal = {arXiv preprint arXiv: Arxiv-2104.12807}
}

@inproceedings{Zhang_2019_CVPR,
  author    = {Zhang, Wenxiao and Xiao, Chunxia},
  title     = {PCAN: 3D Attention Map Learning Using Contextual Information for Point Cloud Based Retrieval},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  month     = {June},
  year      = {2019}
}

@article{kahatapitiya2021swat,
  title   = {SWAT: Spatial Structure Within and Among Tokens},
  author  = {Kumara Kahatapitiya and Michael S. Ryoo},
  year    = {2021},
  journal = {arXiv preprint arXiv: Arxiv-2111.13677}
}

@article{yuan2021contextualized,
  title   = {Contextualized Spatio-Temporal Contrastive Learning with Self-Supervision},
  author  = {Liangzhe Yuan and Rui Qian and Yin Cui and Boqing Gong and Florian Schroff and Ming-Hsuan Yang and Hartwig Adam and Ting Liu},
  year    = {2022},
  journal = {CVPR}
}

@article{wang2022deformable,
  title   = {Deformable Video Transformer},
  author  = {Jue Wang and Lorenzo Torresani},
  year    = {2022},
  journal = {CVPR}
}

@article{shvetsova2021everything,
  title   = {Everything at Once - Multi-modal Fusion Transformer for Video Retrieval},
  author  = {Nina Shvetsova and Brian Chen and Andrew Rouditchenko and Samuel Thomas and Brian Kingsbury and Rogerio Feris and David Harwath and James Glass and Hilde Kuehne},
  year    = {2021},
  journal = {arXiv preprint arXiv: Arxiv-2112.04446}
}

@inproceedings{DBLP:conf/eccv/Gabeur0AS20,
  author    = {Valentin Gabeur and Chen Sun and Karteek Alahari and Cordelia Schmid},
  editor    = {Andrea Vedaldi and Horst Bischof and Thomas Brox and Jan{-}Michael Frahm},
  title     = {Multi-modal Transformer for Video Retrieval},
  booktitle = {Computer Vision - {ECCV} 2020 - 16th European Conference, Glasgow, UK, August 23-28, 2020, Proceedings, Part {IV}},
  series    = {Lecture Notes in Computer Science},
  volume    = {12349},
  pages     = {214-229},
  publisher = {Springer},
  year      = {2020},
  url       = {https://doi.org/10.1007/978-3-030-58548-8\_13},
  doi       = {10.1007/978-3-030-58548-8\_13},
  timestamp = {Thu, 29 Oct 2020 15:25:19 +0100},
  biburl    = {https://dblp.org/rec/conf/eccv/Gabeur0AS20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Recasens_2021_ICCV,
  author    = {Recasens, Adri\`a and Luc, Pauline and Alayrac, Jean-Baptiste and Wang, Luyu and Strub, Florian and Tallec, Corentin and Malinowski, Mateusz and P\u{a}tr\u{a}ucean, Viorica and Altch\'e, Florent and Valko, Michal and Grill, Jean-Bastien and van den Oord, A\"aron and Zisserman, Andrew},
  title     = {Broaden Your Views for Self-Supervised Video Learning},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  month     = {October},
  year      = {2021},
  pages     = {1255-1265}
}

@inproceedings{DBLP:conf/nips/AlayracRSARFSDZ20,
  author    = {Jean{-}Baptiste Alayrac and Adri{\`{a}} Recasens and Rosalia Schneider and Relja Arandjelovic and Jason Ramapuram and Jeffrey De Fauw and Lucas Smaira and Sander Dieleman and Andrew Zisserman},
  editor    = {Hugo Larochelle and Marc'Aurelio Ranzato and Raia Hadsell and Maria{-}Florina Balcan and Hsuan{-}Tien Lin},
  title     = {Self-Supervised MultiModal Versatile Networks},
  booktitle = {Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual},
  year      = {2020},
  url       = {https://proceedings.neurips.cc/paper/2020/hash/0060ef47b12160b9198302ebdb144dcf-Abstract.html},
  timestamp = {Tue, 19 Jan 2021 15:56:58 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/AlayracRSARFSDZ20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{li2021towards,
  title   = {Towards a Unified Foundation Model: Jointly Pre-Training Transformers on Unpaired Images and Text},
  author  = {Qing Li and Boqing Gong and Yin Cui and Dan Kondratyuk and Xianzhi Du and Ming-Hsuan Yang and Matthew Brown},
  year    = {2021},
  journal = {arXiv preprint arXiv: Arxiv-2112.07074}
}

@inproceedings{DBLP:conf/nips/HuangDXCZH21,
  author    = {Yu Huang and Chenzhuang Du and Zihui Xue and Xuanyao Chen and Hang Zhao and Longbo Huang},
  editor    = {Marc'Aurelio Ranzato and Alina Beygelzimer and Yann N. Dauphin and Percy Liang and Jennifer Wortman Vaughan},
  title     = {What Makes Multi-Modal Learning Better than Single (Provably)},
  booktitle = {Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual},
  pages     = {10944-10956},
  year      = {2021},
  url       = {https://proceedings.neurips.cc/paper/2021/hash/5aa3405a3f865c10f420a4a7b55cbff3-Abstract.html},
  timestamp = {Tue, 03 May 2022 16:20:47 +0200},
  biburl    = {https://dblp.org/rec/conf/nips/HuangDXCZH21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/cvpr/YeR0W19,
  author    = {Linwei Ye and Mrigank Rochan and Zhi Liu and Yang Wang},
  title     = {Cross-Modal Self-Attention Network for Referring Image Segmentation},
  booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition, {CVPR} 2019, Long Beach, CA, USA, June 16-20, 2019},
  pages     = {10502-10511},
  publisher = {Computer Vision Foundation / {IEEE}},
  year      = {2019},
  url       = {http://openaccess.thecvf.com/content\_CVPR\_2019/html/Ye\_Cross-Modal\_Self-Attention\_Network\_for\_Referring\_Image\_Segmentation\_CVPR\_2019\_paper.html},
  doi       = {10.1109/CVPR.2019.01075},
  timestamp = {Mon, 30 Aug 2021 17:01:14 +0200},
  biburl    = {https://dblp.org/rec/conf/cvpr/YeR0W19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{yang2022visionlanguage,
  title   = {Vision-Language Pre-Training with Triple Contrastive Learning},
  author  = {Jinyu Yang and Jiali Duan and Son Tran and Yi Xu and Sampath Chanda and Liqun Chen and Belinda Zeng and Trishul Chilimbi and Junzhou Huang},
  year    = {2022},
  journal = {CVPR}
}

@inproceedings{NIPS2017_7a98af17,
  author    = {van den Oord, Aaron and Vinyals, Oriol and kavukcuoglu, koray},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
  publisher = {Curran Associates, Inc.},
  title     = {Neural Discrete Representation Learning},
  url       = {https://proceedings.neurips.cc/paper/2017/file/7a98af17e63a0ac09ce2e96d03992fbc-Paper.pdf},
  volume    = {30},
  year      = {2017}
}

@inproceedings{DBLP:conf/icml/RameshPGGVRCS21,
  author    = {Aditya Ramesh and Mikhail Pavlov and Gabriel Goh and Scott Gray and Chelsea Voss and Alec Radford and Mark Chen and Ilya Sutskever},
  editor    = {Marina Meila and Tong Zhang},
  title     = {Zero-Shot Text-to-Image Generation},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning, {ICML} 2021, 18-24 July 2021, Virtual Event},
  series    = {Proceedings of Machine Learning Research},
  volume    = {139},
  pages     = {8821-8831},
  publisher = {{PMLR}},
  year      = {2021},
  url       = {http://proceedings.mlr.press/v139/ramesh21a.html},
  timestamp = {Wed, 25 Aug 2021 17:11:17 +0200},
  biburl    = {https://dblp.org/rec/conf/icml/RameshPGGVRCS21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/icml/RadfordKHRGASAM21,
  author    = {Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
  editor    = {Marina Meila and Tong Zhang},
  title     = {Learning Transferable Visual Models From Natural Language Supervision},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning, {ICML} 2021, 18-24 July 2021, Virtual Event},
  series    = {Proceedings of Machine Learning Research},
  volume    = {139},
  pages     = {8748-8763},
  publisher = {{PMLR}},
  year      = {2021},
  url       = {http://proceedings.mlr.press/v139/radford21a.html},
  timestamp = {Wed, 25 Aug 2021 17:11:17 +0200},
  biburl    = {https://dblp.org/rec/conf/icml/RadfordKHRGASAM21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/nips/HoJA20,
  author    = {Jonathan Ho and Ajay Jain and Pieter Abbeel},
  editor    = {Hugo Larochelle and Marc'Aurelio Ranzato and Raia Hadsell and Maria{-}Florina Balcan and Hsuan{-}Tien Lin},
  title     = {Denoising Diffusion Probabilistic Models},
  booktitle = {Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual},
  year      = {2020},
  url       = {https://proceedings.neurips.cc/paper/2020/hash/4c5bcfec8584af0d967f1ab10179ca4b-Abstract.html},
  timestamp = {Tue, 19 Jan 2021 15:57:09 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/HoJA20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{saharia2022photorealistic,
  title   = {Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding},
  author  = {Chitwan Saharia and William Chan and Saurabh Saxena and Lala Li and Jay Whang and Emily Denton and Seyed Kamyar Seyed Ghasemipour and Burcu Karagol Ayan and S. Sara Mahdavi and Rapha Gontijo Lopes and Tim Salimans and Jonathan Ho and David J Fleet and Mohammad Norouzi},
  year    = {2022},
  journal = {arXiv preprint arXiv: Arxiv-2205.11487}
}

@article{grill2020bootstrap,
  title     = {Bootstrap your own latent: A new approach to self-supervised Learning},
  author    = {Jean-Bastien Grill and Florian Strub and Florent Altch'e and Corentin Tallec and Pierre H. Richemond and Elena Buchatskaya and Carl Doersch and B. '. Pires and Z. Guo and M. G. Azar and Bilal Piot and K. Kavukcuoglu and R. Munos and Michal Valko},
  journal   = {neurips},
  year      = {2020},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/38f93092ece8eee9771e61c1edaf11b1293cae1b}
}

@inproceedings{DBLP:conf/iclr/DosovitskiyB0WZ21,
  author    = {Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
  title     = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  booktitle = {9th International Conference on Learning Representations, {ICLR} 2021, Virtual Event, Austria, May 3-7, 2021},
  publisher = {OpenReview.net},
  year      = {2021},
  url       = {https://openreview.net/forum?id=YicbFdNTTy},
  timestamp = {Wed, 23 Jun 2021 17:36:39 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/DosovitskiyB0WZ21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/icml/ChenK0H20,
  author    = {Ting Chen and Simon Kornblith and Mohammad Norouzi and Geoffrey E. Hinton},
  title     = {A Simple Framework for Contrastive Learning of Visual Representations},
  booktitle = {Proceedings of the 37th International Conference on Machine Learning, {ICML} 2020, 13-18 July 2020, Virtual Event},
  series    = {Proceedings of Machine Learning Research},
  volume    = {119},
  pages     = {1597-1607},
  publisher = {{PMLR}},
  year      = {2020},
  url       = {http://proceedings.mlr.press/v119/chen20j.html},
  timestamp = {Tue, 15 Dec 2020 17:40:18 +0100},
  biburl    = {https://dblp.org/rec/conf/icml/ChenK0H20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{kahatapitiya2021swat,
  title   = {SWAT: Spatial Structure Within and Among Tokens},
  author  = {Kumara Kahatapitiya and Michael S. Ryoo},
  year    = {2021},
  journal = {arXiv preprint arXiv: Arxiv-2111.13677}
}

@inproceedings{DBLP:conf/nips/NagraniYAJSS21,
  author    = {Arsha Nagrani and Shan Yang and Anurag Arnab and Aren Jansen and Cordelia Schmid and Chen Sun},
  editor    = {Marc'Aurelio Ranzato and Alina Beygelzimer and Yann N. Dauphin and Percy Liang and Jennifer Wortman Vaughan},
  title     = {Attention Bottlenecks for Multimodal Fusion},
  booktitle = {Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual},
  pages     = {14200-14213},
  year      = {2021},
  url       = {https://proceedings.neurips.cc/paper/2021/hash/76ba9f564ebbc35b1014ac498fafadd0-Abstract.html},
  timestamp = {Tue, 03 May 2022 16:20:48 +0200},
  biburl    = {https://dblp.org/rec/conf/nips/NagraniYAJSS21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{oord2018representation,
  title   = {Representation Learning with Contrastive Predictive Coding},
  author  = {Aaron van den Oord and Yazhe Li and Oriol Vinyals},
  year    = {2018},
  journal = {arXiv preprint arXiv: Arxiv-1807.03748}
}

@inproceedings{DBLP:conf/icml/ZbontarJMLD21,
  author    = {Jure Zbontar and Li Jing and Ishan Misra and Yann LeCun and St{\'{e}}phane Deny},
  editor    = {Marina Meila and Tong Zhang},
  title     = {Barlow Twins: Self-Supervised Learning via Redundancy Reduction},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning, {ICML} 2021, 18-24 July 2021, Virtual Event},
  series    = {Proceedings of Machine Learning Research},
  volume    = {139},
  pages     = {12310-12320},
  publisher = {{PMLR}},
  year      = {2021},
  url       = {http://proceedings.mlr.press/v139/zbontar21a.html},
  timestamp = {Wed, 25 Aug 2021 17:11:17 +0200},
  biburl    = {https://dblp.org/rec/conf/icml/ZbontarJMLD21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/mt/SulubacakCGREST20,
  author    = {Umut Sulubacak and Ozan Caglayan and Stig{-}Arne Gr{\"{o}}nroos and Aku Rouhe and Desmond Elliott and Lucia Specia and J{\"{o}}rg Tiedemann},
  title     = {Multimodal machine translation through visuals and speech},
  journal   = {Mach. Transl.},
  volume    = {34},
  number    = {2-3},
  pages     = {97-147},
  year      = {2020},
  url       = {https://doi.org/10.1007/s10590-020-09250-0},
  doi       = {10.1007/s10590-020-09250-0},
  timestamp = {Wed, 01 Sep 2021 12:45:25 +0200},
  biburl    = {https://dblp.org/rec/journals/mt/SulubacakCGREST20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/nips/VaswaniSPUJGKP17,
  author    = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
  editor    = {Isabelle Guyon and Ulrike von Luxburg and Samy Bengio and Hanna M. Wallach and Rob Fergus and S. V. N. Vishwanathan and Roman Garnett},
  title     = {Attention is All you Need},
  booktitle = {Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, {USA}},
  pages     = {5998-6008},
  year      = {2017},
  url       = {https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html},
  timestamp = {Thu, 21 Jan 2021 15:15:21 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/VaswaniSPUJGKP17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}